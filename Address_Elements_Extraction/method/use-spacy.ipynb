{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pandarallel\n!pip install pyahocorasick\n!pip install --upgrade pip\n!pip install spacy==3.0.*","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_colwidth', None)\n\nfrom pandarallel import pandarallel\npandarallel.initialize()\n\nimport spacy\n# spacy.require_gpu()\nfrom spacy.training import Example\nfrom spacy.util import minibatch\nimport random\n\nimport ahocorasick","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/scl-2021-ds/train.csv\")\ndf.set_index(\"id\", inplace=True)\ndf['POI'] = np.nan\ndf['street'] = np.nan\n\ndef extract_entities(row):\n    extracted = row['POI/street'].split(\"/\")\n    \n    if len(extracted) == 2:\n        poi, street = extracted\n        if poi.strip() != '':\n            row['POI'] = poi\n        \n        if street.strip() != '':\n            row['street'] = street\n        \n    return row\n\ndf = df.parallel_apply(extract_entities, axis=1)\nnlp = spacy.blank('id')  # create blank Language class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from copy import deepcopy\n\ndef _build_aho(words):\n    aho = ahocorasick.Automaton()\n    for idx, key in enumerate(words):\n        aho.add_word(key, (idx, key))\n\n    return aho\n\ndef format_data(text, poi, street):\n    entities = []\n    _text = deepcopy(text)\n\n    if isinstance(poi, str):\n        aho = _build_aho([poi])\n        aho.make_automaton()\n        latest_char_idx = 0\n        \n        for end, (_, word) in aho.iter(_text):\n            start = end - len(word) + 1\n            if start < latest_char_idx:\n                continue\n\n            entities.append((start, end + 1, 'POI'))\n            _text = _text.replace(word, \" \" * len(word))\n            latest_char_idx = end + 1\n        \n    if isinstance(street, str):\n        aho = _build_aho([street])\n        aho.make_automaton()\n        latest_char_idx = 0\n\n        for end, (_, word) in aho.iter(_text):\n            start = end - len(word) + 1\n            if start < latest_char_idx:\n                continue\n\n            entities.append((start, end + 1, 'STREET'))\n            latest_char_idx = end + 1\n    \n    return Example.from_dict(nlp.make_doc(text), {\"entities\": entities})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Preparing Spacy examples...\")\n\nexamples = []\nfor idx in df.index:\n    try:\n        row = df.loc[idx]\n        example = format_data(row['raw_address'], row['POI'], row['street'])\n        examples.append(example)\n    except Exception as e:\n        print(idx)\n        print(\"-\" * 50)\n        print(e)\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_spacy(nlp, examples, iterations):\n    \n    TRAIN_DATA = examples\n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if 'ner' not in nlp.pipe_names:\n        ner = nlp.add_pipe('ner', last=True)\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        optimizer = nlp.begin_training()\n        for itn in range(iterations):\n            print(\"Starting iteration \" + str(itn))\n            random.shuffle(examples)\n            batches = minibatch(examples, 1000)\n            losses = {}\n            for batch in batches:\n                nlp.update(\n                    batch,\n                    drop=0.2,  # dropout - make it harder to memorise data\n                    sgd=optimizer,  # callable to update weights\n                    losses=losses)\n            print(losses)\n    return nlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = examples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nner_nlp = train_spacy(nlp, train, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, row in df.iloc[100:110].iterrows():\n    print(f\"address: {row['raw_address']}\")\n    print(f\"expected poi: {row['POI']}\")\n    print(f\"expected street: {row['street']}\")\n    print()\n    \n    doc = ner_nlp(row['raw_address'])\n    for ent in doc.ents:\n        print(ent.text, \"-\", ent.label_)\n\n    print(\"-\" * 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/scl-2021-ds/test.csv\")\ndf_test.set_index(\"id\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = []\nfor idx, row in df_test.iloc[:].iterrows():\n    doc = ner_nlp(row['raw_address'])\n    tmp = {'id': idx}\n    for ent in doc.ents:\n        tmp[ent.label_] = ent.text\n    submission.append(tmp)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(submission)\nsubmission['POI'] = submission['POI'].replace(np.nan, '')\nsubmission['STREET'] = submission['STREET'].replace(np.nan, '')\nsubmission['POI/street'] = submission['POI'] + '/' + submission['STREET'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({'id':submission['id'],'POI/street':submission['POI/street']}).to_csv('submission.csv', header=True, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}